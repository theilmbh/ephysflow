{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer: passaro\n"
     ]
    }
   ],
   "source": [
    "# tampering with the kwd file on passaro\n",
    "# the /experiment folder is on the ssd of passaro (/usr/local/experiment/raw_data)\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pdb\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.signal as sg\n",
    "import math\n",
    "import scipy as sp\n",
    "import socket\n",
    "import os\n",
    "import wave\n",
    "import struct\n",
    "import h5py\n",
    "from scipy.signal import hilbert\n",
    "from basic_viewing import h5_functions as h5\n",
    "import glob\n",
    "import errno    \n",
    "import os\n",
    "import shutil as sh\n",
    "import yaml\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# Check wihic computer to decide where the things are mounted\n",
    "comp_name=socket.gethostname()\n",
    "print 'Computer: ' + comp_name\n",
    "if  comp_name == 'chim':\n",
    "    #sys.path.append('/Users/zeke/experiment/ephysDataManagement/ephysScripts')\n",
    "    experiment_folder = os.path.join(os.path.abspath('W:') , \"earneodo\", \"bci_zf\")\n",
    "elif  'lookfar' in comp_name:\n",
    "    repos_folder = os.path.abspath('/Users/zeke/reposs')\n",
    "    experiment_folder = os.path.join(os.path.abspath('/Volumes'), \n",
    "                                     'gentner', \n",
    "                                     'earneodo', \n",
    "                                     'bci_zf')\n",
    "\n",
    "elif 'lintu' in comp_name:\n",
    "    repos_folder = os.path.abspath('/mnt/cube/earneodo/repos')\n",
    "    experiment_folder = os.path.join('/mnt/cube/earneodo/bci_zf/')\n",
    "\n",
    "elif 'passaro' in comp_name:\n",
    "    repos_folder = os.path.abspath('/mnt/cube/earneodo/repos')\n",
    "    cube_experiment_folder = os.path.join('/mnt/cube/earneodo/bci_zf/')\n",
    "    store_experiment_folder = os.path.join('/Data/bci_zf/')\n",
    "    experiment_folder = os.path.join('/usr/local/experiment')\n",
    "\n",
    "sys.path.append(os.path.join(repos_folder, 'soundflow', 'sound_tools'))\n",
    "sys.path.append(os.path.join(repos_folder, 'ephysflow'))\n",
    "sys.path.append(os.path.join(repos_folder, 'analysis-tools'))\n",
    "\n",
    "import soundtools as st\n",
    "import Kwik as oe\n",
    "from scipy.io import wavfile\n",
    "from file_tools import experiment as et\n",
    "\n",
    "def create_neural_data_set(data_set, parent_group, channel_list, \n",
    "                           frame_size=None, \n",
    "                           processing=None,\n",
    "                           *args, **kwargs):\n",
    "    # make the new dataset\n",
    "    d_type = data_set.dtype\n",
    "    nd_cols = np.array(channel_list).size\n",
    "    nd_rows = data_set.shape[0]\n",
    "    d_chunks = np.array(data_set.chunks)\n",
    "    \n",
    "    if d_chunks[0] > nd_rows:\n",
    "        d_chunks[0] = nd_rows\n",
    "    \n",
    "    if frame_size is None:\n",
    "        frame_size = d_chunks[0] if d_chunks[0]<nd_rows else nd_rows\n",
    "    \n",
    "    neural_dset = parent_group.create_dataset(\"data\", (nd_rows, nd_cols), \n",
    "                                              chunks=(d_chunks[0], nd_cols), dtype=d_type)\n",
    "    \n",
    "    copy_frame = np.zeros([frame_size, nd_cols], dtype=d_type)\n",
    "    n_full_frames = int(data_set.shape[0]/frame_size)\n",
    "    #print neural_dset.shape\n",
    "    # Fill the dataset:\n",
    "    for i in range(n_full_frames):\n",
    "        copy_frame = h5.load_table_slice(data_set, \n",
    "                                         np.arange(i*frame_size, (i+1)*frame_size), \n",
    "                                         channel_list)\n",
    "        neural_dset[i*frame_size: (i+1)*frame_size, 0:nd_cols] = copy_frame\n",
    "    \n",
    "    if frame_size*n_full_frames < nd_rows:\n",
    "        last_frame_size = nd_rows - frame_size*n_full_frames\n",
    "        copy_frame = np.zeros([last_frame_size, nd_cols], dtype=d_type)\n",
    "        copy_frame = h5.load_table_slice(data_set, \n",
    "                                         np.arange(n_full_frames*frame_size, \n",
    "                                                   n_full_frames*frame_size + last_frame_size),\n",
    "                                         channel_list)\n",
    "    # copy the attributes:\n",
    "    neural_dset.attrs.create('valid_samples', \n",
    "                             np.array(data_set.attrs['valid_samples'][channel_list]))\n",
    "    \n",
    "def copy_attribs(source, dest):\n",
    "    for key, attrib in source.attrs.iteritems():\n",
    "        dest.attrs.create(key, attrib, dtype=attrib.dtype)\n",
    "        \n",
    "def copy_application_data(source_rec, dest_rec, chan_list,\n",
    "                          resize_keys = ['channel_bit_volts', 'channel_sample_rates']):\n",
    "    \n",
    "    dest_rec.create_group('application_data')\n",
    "    for key, attrib in source_rec['application_data'].attrs.iteritems():\n",
    "        if not key in resize_keys:\n",
    "            dest_rec['application_data'].attrs.create(key, attrib, dtype=attrib.dtype)\n",
    "        else:\n",
    "            #print key\n",
    "            #print attrib[chan_list]\n",
    "            dest_rec['application_data'].attrs.create(key, attrib[chan_list], dtype=attrib.dtype)\n",
    "\n",
    "def check_rec_data(source_rec):\n",
    "    #check the data table of a rec group\n",
    "    data_set = source_rec['data']\n",
    "    valid_samples = None\n",
    "    try:\n",
    "        valid_samples = data_set.attrs.get('valid_samples')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    has_data = True if valid_samples is not None and valid_samples[0]>0 else False\n",
    "    return has_data\n",
    "\n",
    "def get_valid_samples(source_rec):\n",
    "    #get the valid samples declared by the data table attributes\n",
    "    data_set = source_rec['data']\n",
    "    valid_samples = None\n",
    "    try:\n",
    "        valid_samples = data_set.attrs.get('valid_samples')[0]\n",
    "    except:\n",
    "        pass\n",
    "    return valid_samples\n",
    "\n",
    "def create_data_groups(raw_file, new_file, chan_list):\n",
    "    for rec_name, rec_group in raw_file['/recordings'].iteritems():\n",
    "        new_file['/recordings'].create_group(rec_name)\n",
    "        copy_attribs(rec_group, new_file['/recordings'][rec_name])\n",
    "        copy_application_data(rec_group, new_file['/recordings'][rec_name], chan_list)\n",
    "        create_neural_data_set(rec_group['data'], new_file['/recordings'][rec_name], chan_list)\n",
    "        \n",
    "def make_shank_kwd(raw_file, out_file_path, chan_list):\n",
    "    ss_file = h5py.File(out_file_path, 'w')\n",
    "    copy_attribs(raw_file, ss_file)\n",
    "    ss_file.create_group('/recordings')\n",
    "    create_data_groups(raw_file, ss_file, chan_list) \n",
    "    ss_file.close()\n",
    "    \n",
    "def list_flatten(x):\n",
    "    return [val for sublist in x for val in sublist]\n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "def make_super_file(path):\n",
    "    new_file = h5py.File(path, 'w')\n",
    "    new_file.create_group('/recordings')\n",
    "    new_file.close()\n",
    "\n",
    "def create_data_group(raw_file, new_file, chan_list, new_rec_name):\n",
    "    for rec_name, rec_group in raw_file['/recordings'].iteritems():\n",
    "        new_file['/recordings'].create_group(rec_name)\n",
    "        copy_attribs(rec_group, new_file['/recordings'][rec_name])\n",
    "        copy_application_data(rec_group, new_file['/recordings'][rec_name], chan_list)\n",
    "        create_neural_data_set(rec_group['data'], new_file['/recordings'][rec_name], chan_list)\n",
    "\n",
    "def insert_neural_rec_group(dest_file, raw_rec_group, chan_list, new_group_name=None):\n",
    "    rec_name = raw_rec_group.name if new_group_name is None else new_group_name\n",
    "    \n",
    "    dest_file['/recordings'].create_group(rec_name)\n",
    "    new_rec = dest_file['/recordings'][rec_name]\n",
    "    copy_application_data(raw_rec_group, new_rec, chan_list)\n",
    "    copy_attribs(raw_rec_group, new_rec)\n",
    "    create_neural_data_set(raw_rec_group['data'], new_rec, chan_list)\n",
    "    \n",
    "def modify_rec_group_attribs(kwd_file, rec_name, attr_dict, new_attr_dict = None):\n",
    "    for key, value in attr_dict.iteritems():\n",
    "        kwd_file['/recordings'][rec_name].attrs.modify(key, value)\n",
    "    \n",
    "    if new_attr_dict is not None:\n",
    "        for key, value in new_attr_dict.iteritems():\n",
    "            kwd_file['/recordings'][rec_name].attrs.create(key, value)\n",
    "\n",
    "def get_recs_list(experiment_file):\n",
    "    if experiment_file['/recordings'].keys() == []:\n",
    "        rec_list = None\n",
    "    else:\n",
    "        rec_list = np.array([int(i) for i in experiment_file['/recordings'].keys()])\n",
    "    return rec_list\n",
    "\n",
    "def get_experiment_endpoints(experiment_file):\n",
    "    recs_list = get_recs_list(experiment_file)\n",
    "    if recs_list is not None:\n",
    "        last_rec_num = np.max(recs_list)\n",
    "        last_rec_name = str(last_rec_num)\n",
    "        last_rec = experiment_file['/recordings'][last_rec_name]\n",
    "        last_rec_start = last_rec.attrs['start_sample']\n",
    "        last_rec_nsamples = last_rec['data'].shape[0]\n",
    "        next_rec_num = last_rec_num + 1\n",
    "        next_sample = last_rec_start + last_rec_nsamples\n",
    "    else:\n",
    "        next_rec_num = 0\n",
    "        next_sample = 0\n",
    "        \n",
    "    return [next_rec_num, next_sample]\n",
    "            \n",
    "\n",
    "def insert_experiment_groups(dest_file, raw_file, chan_list):\n",
    "    # all the recs in an experiment file if they pass check\n",
    "    for raw_rec_name, raw_rec_group in raw_file['/recordings'].iteritems():\n",
    "        #print 'rec {0}'.format(raw_rec_name)\n",
    "        s_f = raw_rec_group.attrs['sample_rate']\n",
    "        if check_rec_data(raw_rec_group):\n",
    "            target_rec_num, target_start_sample = get_experiment_endpoints(dest_file)\n",
    "            target_rec_name = str(target_rec_num)\n",
    "            target_start_time = int(target_start_sample/(0.001*s_f))\n",
    "            target_source = '{0}:''/''recordings/{1}'.format(raw_file.filename, raw_rec_name)\n",
    "            insert_neural_rec_group(dest_file, raw_rec_group, chan_list, new_group_name=target_rec_name)\n",
    "            modify_rec_group_attribs(dest_file, target_rec_name, \n",
    "                             {'start_sample' : target_start_sample},\n",
    "                              new_attr_dict = {'name' : target_source,\n",
    "                                               'start_time' : target_start_time})\n",
    "        else:\n",
    "            #print \"Skipping rec {0} with no data\".format(raw_rec_name)\n",
    "            pass\n",
    "\n",
    "def band_pass_filter_pars(s_f, exp_par):\n",
    "    filt_hi = exp_par['search_motiff']['filt_hi']\n",
    "    filt_lo = exp_par['search_motiff']['filt_lo']\n",
    "    hp_b, hp_a = sg.butter(4, filt_hi/(s_f/2.), btype='high')\n",
    "    lp_b, lp_a = sg.butter(4, filt_lo/(s_f/2.), btype='low')\n",
    "    return hp_b, hp_a, lp_b, lp_a\n",
    "\n",
    "def filter_bp(data, hp_b, hp_a, lp_b, lp_a):\n",
    "    x_hi = sg.filtfilt(hp_b, hp_a, data, axis=0)\n",
    "    x_lo = sg.filtfilt(lp_b, lp_a, x_hi, axis=0)\n",
    "    return x_lo\n",
    "\n",
    "def get_dset_group_attr(data_set, attr_name):\n",
    "    return data_set.parent.attrs[attr_name]\n",
    "\n",
    "def export_audio(data_set, chan_number, out_file_path, filter_func=None, args=(), **kwargs):\n",
    "    frame_size = 60 #seconds\n",
    "    s_f = get_dset_group_attr(data_set, 'sample_rate')\n",
    "    samples_frame = int(frame_size * s_f)\n",
    "    samples_data = data_set.shape[0]\n",
    "    \n",
    "    frame_buffer = np.zeros((samples_frame, 1), dtype = np.float)\n",
    "    frame_starts = np.arange(0, samples_data, samples_frame)\n",
    "    \n",
    "    wavefile = wave.open(out_file_path,'wb')\n",
    "    wavefile.setparams((1, 2, s_f, 0, 'NONE', 'not compressed'))\n",
    "    \n",
    "    for start in frame_starts:\n",
    "        end = min(start + samples_frame, samples_data)\n",
    "        frame_buffer[0: end-start, :] = h5.load_table_slice(data_set, \n",
    "                                                         np.arange(start, end),\n",
    "                                                         [chan_number])\n",
    "        frame_buffer[0:end-start, :] = filter_func(frame_buffer[0:end-start, :], \n",
    "                                                  *args, **kwargs)\n",
    "        wavefile.writeframes(frame_buffer[0: end-start].astype('h').tostring())\n",
    "    \n",
    "    wavefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/usr/local/experiment/raw_data/z017/2016-07-13_17-23-17_300']\n"
     ]
    }
   ],
   "source": [
    "bird_id = 'z017'\n",
    "sess_day = '2016-07-13'\n",
    "depth = 300\n",
    "\n",
    "channel_config = {'neural': [0, 11, 9, 16, 14, 5, 8, 10, 15, 2, 7, 4, 3, 5, 1, 16, 15],\n",
    "                  'super' : range(17),\n",
    "                  '0' : [11, 15, 8, 10],\n",
    "                  '1' : [14, 9, 13, 12],\n",
    "                  '2' : [2, 3, 1, 6],\n",
    "                  '3' : [5, 7, 0, 4], \n",
    "                  'test' : [11],\n",
    "                  'mic': [16]}\n",
    "\n",
    "chan_list= channel_config['super']\n",
    "# Make the super session and gather the list of sessions\n",
    "# get the sessions list of files\n",
    "fn = et.file_names(bird_id, sess_day)\n",
    "\n",
    "raw_data_folder = os.path.join(experiment_folder, 'raw_data')\n",
    "ss_data_folder = os.path.join(cube_experiment_folder, 'ss_data')\n",
    "\n",
    "sessions = glob.glob(os.path.join(raw_data_folder, bird_id, sess_day + '*' + str(depth)))\n",
    "experiments = list_flatten([ glob.glob(os.path.join(s, '*.raw.kwd'))[:] for s in sessions ])\n",
    "experiments.sort()\n",
    "sessions = glob.glob(os.path.join(raw_data_folder, bird_id, sess_day + '*' + str(depth)))\n",
    "print sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/usr/local/experiment/raw_data/z017/2016-07-12_13-44-59_225/experiment.par.yml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-0a2ac7485532>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m sess_par = et.get_parameters(bird_id, os.path.split(os.path.split(experiment_path)[0])[1], \n\u001b[1;32m----> 8\u001b[1;33m                             location='raw')\n\u001b[0m",
      "\u001b[1;32m/mnt/cube/earneodo/repos/ephysflow/file_tools/experiment.py\u001b[0m in \u001b[0;36mget_parameters\u001b[1;34m(bird, sess, rec, experiment_folder, location)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_folder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbird\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'folders'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'files'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'par'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mpars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/usr/local/experiment/raw_data/z017/2016-07-12_13-44-59_225/experiment.par.yml'"
     ]
    }
   ],
   "source": [
    "# get the parameter file of the first rec in the day\n",
    "super_sess_name = 'day-' + sess_day\n",
    "fn = et.file_names(bird_id, super_sess_name, 0)\n",
    "super_sess_path = fn['folders']['ss']\n",
    "super_file_path = os.path.join(super_sess_path, fn['files']['ss_raw'])\n",
    "\n",
    "sess_par = et.get_parameters(bird_id, os.path.split(os.path.split(experiment_path)[0])[1], \n",
    "                            location='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making supersession day-2016-07-13\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-13/experiment.raw.kwd\n"
     ]
    }
   ],
   "source": [
    "bird_id = 'z017'\n",
    "sess_day = '2016-07-12'\n",
    "depth = 225\n",
    "\n",
    "channel_config = {'neural': [0, 11, 9, 16, 14, 5, 8, 10, 15, 2, 7, 4, 3, 5, 1, 16, 15],\n",
    "                  'super' : range(17),\n",
    "                  '0' : [11, 15, 8, 10],\n",
    "                  '1' : [14, 9, 13, 12],\n",
    "                  '2' : [2, 3, 1, 6],\n",
    "                  '3' : [5, 7, 0, 4], \n",
    "                  'test' : [11],\n",
    "                 'sound': [17]}\n",
    "\n",
    "chan_list= channel_config['super']\n",
    "# Make the super session and gather the list of sessions\n",
    "# get the sessions list of files\n",
    "sessions = glob.glob(os.path.join(raw_data_folder, bird_id, sess_day + '*' + str(depth)))\n",
    "experiments = list_flatten([ glob.glob(os.path.join(s, '*.raw.kwd'))[:] for s in sessions ])\n",
    "experiments.sort()\n",
    "\n",
    "# make the supersession file\n",
    "super_sess_name = 'day-' + sess_day\n",
    "fn = et.file_names(bird_id, super_sess_name, 0)\n",
    "super_sess_path = fn['folders']['ss']\n",
    "super_file_path = os.path.join(super_sess_path, fn['files']['ss_raw'])\n",
    "\n",
    "print \"Making supersession {}\".format(super_sess_name)\n",
    "print super_file_path\n",
    "mkdir_p(super_sess_path)\n",
    "super_file = h5py.File(super_file_path, 'a')\n",
    "exp_par_file = \n",
    "for experiment_path in experiments:\n",
    "    print 'File {0}'.format(experiment_path)\n",
    "    sess_fold = os.path.split(os.path.split(experiment_path)[0])[1]\n",
    "    print sess_fold\n",
    "    sess_par = et.get_parameters(bird_id, sess_fold, location='raw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/experiment/raw_data/z017/2016-07-13_17-23-17_300/experiment.par.yml'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_par_file_path = os.path.join(sessions[0], fn['files']['par'])\n",
    "sh.copy2(day_par_file_path, super_sess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_par['channel_config']['neural'] + [sess_par['channel_config']['mic'], ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mic': 16, 'neural': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_par['channel_config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making supersession day-2016-07-12\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-12/experiment.raw.kwd\n",
      "File /usr/local/experiment/raw_data/z017/2016-07-12_09-45-21_225/experiment1_100.raw.kwd\n",
      "2016-07-12_09-45-21_225\n",
      "File /usr/local/experiment/raw_data/z017/2016-07-12_11-01-09_225/experiment1_100.raw.kwd\n",
      "2016-07-12_11-01-09_225\n",
      "File /usr/local/experiment/raw_data/z017/2016-07-12_11-01-09_225/experiment2_100.raw.kwd\n",
      "2016-07-12_11-01-09_225\n",
      "File /usr/local/experiment/raw_data/z017/2016-07-12_13-12-09_225/experiment1_100.raw.kwd\n",
      "2016-07-12_13-12-09_225\n",
      "File /usr/local/experiment/raw_data/z017/2016-07-12_13-44-59_225/experiment1_100.raw.kwd\n",
      "2016-07-12_13-44-59_225\n",
      "cube backup: 2016-07-12_13-44-59_225\n",
      "passaro Data backup: 2016-07-12_13-44-59_225\n",
      "cube backup: 2016-07-12_11-01-09_225\n",
      "passaro Data backup: 2016-07-12_11-01-09_225\n",
      "cube backup: 2016-07-12_13-12-09_225\n",
      "passaro Data backup: 2016-07-12_13-12-09_225\n",
      "cube backup: 2016-07-12_09-45-21_225\n",
      "passaro Data backup: 2016-07-12_09-45-21_225\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "bird_id = 'z017'\n",
    "sess_day = '2016-07-13'\n",
    "depth = 300\n",
    "\n",
    "# Make the super session and gather the list of sessions\n",
    "# get the sessions list of files\n",
    "sessions = glob.glob(os.path.join(raw_data_folder, bird_id, sess_day + '*' + str(depth)))\n",
    "experiments = list_flatten([ glob.glob(os.path.join(s, '*.raw.kwd'))[:] for s in sessions ])\n",
    "experiments.sort()\n",
    "\n",
    "# make the supersession file\n",
    "super_sess_name = 'day-' + sess_day\n",
    "fn = et.file_names(bird_id, super_sess_name, 0)\n",
    "super_sess_path = fn['folders']['ss']\n",
    "super_file_path = os.path.join(super_sess_path, fn['files']['ss_raw'])\n",
    "\n",
    "print \"Making supersession {}\".format(super_sess_name)\n",
    "print super_file_path\n",
    "mkdir_p(super_sess_path)\n",
    "print \"Copying parameter file: \"\n",
    "day_par_file_path = os.path.join(sessions[0], fn['files']['par'])\n",
    "sh.copy2(day_par_file_path, super_sess_path)\n",
    "print \"making the superfile\"\n",
    "super_file = h5py.File(super_file_path, 'a')\n",
    "for experiment_path in experiments:\n",
    "    print 'File {0}'.format(experiment_path)\n",
    "    sess_fold = os.path.split(os.path.split(experiment_path)[0])[1]\n",
    "    print sess_fold\n",
    "    sess_par = et.get_parameters(bird_id, sess_fold, location='raw')\n",
    "    chan_list = sess_par['channel_config']['neural'] + [sess_par['channel_config']['mic'], ]\n",
    "    raw_file = h5py.File(experiment_path, 'r')\n",
    "    insert_experiment_groups(super_file, raw_file, chan_list)\n",
    "    raw_file.close()\n",
    "    super_file.flush()\n",
    "\n",
    "super_file.close()\n",
    "\n",
    "#make the backups\n",
    "bkp_dest_path = os.path.join(cube_experiment_folder, 'raw_data', bird_id)\n",
    "store_dest_path = os.path.join(store_experiment_folder, 'raw_data', bird_id)\n",
    "\n",
    "mkdir_p(bkp_dest_path)\n",
    "mkdir_p(store_dest_path)\n",
    "for session_path in sessions:\n",
    "    session_name = os.path.split(session_path)[-1]\n",
    "    print \"cube backup: \" + session_name\n",
    "    dest_bkp = os.path.join(bkp_dest_path, session_name)\n",
    "    try:\n",
    "        sh.copytree(session_path, dest_bkp)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == 17:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "            \n",
    "    print \"passaro Data backup: \" + session_name\n",
    "    sh.move(session_path, store_dest_path)\n",
    "    \n",
    "extract_wav_chans(bird_id, sess_day)\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Closed HDF5 file>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# copy the first parameter file of the session to the supersession path\n",
    "exp_par = et.get_parameters(bird_id, super_sess_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0', u'1', u'2', u'3', u'4']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_000.mic.wav\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_001.mic.wav\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_002.mic.wav\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_003.mic.wav\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_004.mic.wav\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_004.mic.wav\n"
     ]
    }
   ],
   "source": [
    "fn = et.file_names(bird_id, super_sess_name, 0)\n",
    "super_file_path = os.path.join(fn['folders']['ss'], fn['files']['ss_raw'])\n",
    "\n",
    "super_file = h5py.File(super_file_path, 'r')\n",
    "rec_list = super_file['/recordings'].keys()\n",
    "print rec_list\n",
    "\n",
    "ch_name = 'mic'\n",
    "\n",
    "for rec, rec_grp in super_file['/recordings'].iteritems():\n",
    "    print rec\n",
    "    fn = et.file_names(bird_id, super_sess_name, int(rec))\n",
    "    data_set = rec_grp['data']\n",
    "    s_f = rec_grp.attrs['sample_rate']\n",
    "    wav_file_path = os.path.join(fn['folders']['ss'], fn['files'][ch_name])\n",
    "    print wav_file_path\n",
    "    export_audio(data_set, exp_par['channel_config'][ch_name], wav_file_path,\n",
    "                filter_func=filter_bp,\n",
    "                args=band_pass_filter_pars(s_f, exp_par))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0', u'1', u'2', u'3', u'4']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-12/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-12/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-12/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-12/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-12/experiment-rec_004.mic.wav\n"
     ]
    }
   ],
   "source": [
    "def extract_wav_chans(bird, sess, ch_name='mic'):\n",
    "    fn = et.file_names(bird, sess, 0)\n",
    "    super_file_path = os.path.join(fn['folders']['ss'], fn['files']['ss_raw'])\n",
    "    exp_par = et.get_parameters(bird_id, super_sess_name)\n",
    "    super_file = h5py.File(super_file_path, 'r')\n",
    "    rec_list = super_file['/recordings'].keys()\n",
    "    print rec_list\n",
    "\n",
    "    for rec, rec_grp in super_file['/recordings'].iteritems():\n",
    "        print rec\n",
    "        fn = et.file_names(bird, sess, int(rec))\n",
    "        data_set = rec_grp['data']\n",
    "        s_f = rec_grp.attrs['sample_rate']\n",
    "        wav_file_path = os.path.join(fn['folders']['ss'], fn['files'][ch_name])\n",
    "        print wav_file_path\n",
    "        export_audio(data_set, exp_par['channel_config'][ch_name], wav_file_path,\n",
    "                    filter_func=filter_bp,\n",
    "                    args=band_pass_filter_pars(s_f, exp_par))\n",
    "\n",
    "\n",
    "extract_wav_chans('z017', 'day-2016-07-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0', u'1', u'2', u'3', u'4', u'5', u'6', u'7']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_005.mic.wav\n",
      "6\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_006.mic.wav\n",
      "7\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-22/experiment-rec_007.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-23/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-23/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-23/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-23/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-23/experiment-rec_004.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-24/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-24/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-24/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-24/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-24/experiment-rec_004.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-25/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-25/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-25/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-25/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-25/experiment-rec_004.mic.wav\n",
      "[u'0', u'1', u'10', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_001.mic.wav\n",
      "10\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_010.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_005.mic.wav\n",
      "6\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_006.mic.wav\n",
      "7\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_007.mic.wav\n",
      "8\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_008.mic.wav\n",
      "9\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-28/experiment-rec_009.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4', u'5', u'6', u'7']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_005.mic.wav\n",
      "6\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_006.mic.wav\n",
      "7\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-29/experiment-rec_007.mic.wav\n",
      "[u'0', u'1', u'2', u'3']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-30/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-30/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-30/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-06-30/experiment-rec_003.mic.wav\n",
      "[u'0', u'1', u'10', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_001.mic.wav\n",
      "10\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_010.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_005.mic.wav\n",
      "6\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_006.mic.wav\n",
      "7\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_007.mic.wav\n",
      "8\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_008.mic.wav\n",
      "9\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-01/experiment-rec_009.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4', u'5']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-05/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-05/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-05/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-05/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-05/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-05/experiment-rec_005.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4', u'5', u'6', u'7']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_005.mic.wav\n",
      "6\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_006.mic.wav\n",
      "7\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-06/experiment-rec_007.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4', u'5']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-07/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-07/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-07/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-07/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-07/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-07/experiment-rec_005.mic.wav\n",
      "[u'0', u'1', u'2', u'3', u'4']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-08/experiment-rec_004.mic.wav\n",
      "[]\n",
      "[u'0', u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9']\n",
      "0\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_000.mic.wav\n",
      "1\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_001.mic.wav\n",
      "2\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_002.mic.wav\n",
      "3\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_003.mic.wav\n",
      "4\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_004.mic.wav\n",
      "5\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_005.mic.wav\n",
      "6\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_006.mic.wav\n",
      "7\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_007.mic.wav\n",
      "8\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_008.mic.wav\n",
      "9\n",
      "/mnt/cube/earneodo/bci_zf/ss_data/z017/day-2016-07-11/experiment-rec_009.mic.wav\n"
     ]
    }
   ],
   "source": [
    "days = ['day-2016-06-22', 'day-2016-06-23', 'day-2016-06-24', 'day-2016-06-25',\n",
    "        'day-2016-06-28', 'day-2016-06-29', 'day-2016-06-30', 'day-2016-07-01',\n",
    "        'day-2016-07-05', 'day-2016-07-06', 'day-2016-07-07', 'day-2016-07-08',\n",
    "        'day-2016-07-09', 'day-2016-07-11']\n",
    "\n",
    "for day in days:\n",
    "    extract_wav_chans('z017', day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
