{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer: passaro\n"
     ]
    }
   ],
   "source": [
    "# Definitions and functions\n",
    "%matplotlib inline\n",
    "from __future__ import division\n",
    "import pdb\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.signal as sg\n",
    "import math\n",
    "import scipy as sp\n",
    "import socket\n",
    "import os\n",
    "import wave\n",
    "import struct\n",
    "import h5py\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram\n",
    "import logging\n",
    "from IPython.display import display\n",
    "matplotlib.style.use('ggplot')\n",
    "from ipywidgets import *\n",
    "import yaml\n",
    "import numpy.lib.recfunctions as rfn \n",
    "import numpy.matlib as npm\n",
    "import glob\n",
    "from __future__ import division\n",
    "# Check wich computer to decide where the things are mounted\n",
    "comp_name=socket.gethostname()\n",
    "print('Computer: ' + comp_name)\n",
    "\n",
    "if 'txori' in comp_name or 'passaro' in comp_name or 'lintu' in comp_name:\n",
    "    repos_folder = os.path.abspath('/mnt/cube/earneodo/repos')\n",
    "    experiment_folder = os.path.join('/mnt/cube/earneodo/bci_zf/')\n",
    "\n",
    "sys.path.append(os.path.join(repos_folder, 'soundflow', 'sound_tools'))\n",
    "sys.path.append(os.path.join(repos_folder, 'ephysflow'))\n",
    "sys.path.append(os.path.join(repos_folder, 'swissknife'))\n",
    "\n",
    "\n",
    "import soundtools as st\n",
    "from bci.core import expstruct as et\n",
    "from bci.core import kwik_functions as kwkf\n",
    "from bci.core.file import h5_functions as h5f\n",
    "from bci import synthetic as syn\n",
    "from bci import unitmeta as um\n",
    "from bci import stimalign as sta\n",
    "\n",
    "from basic_viewing import events as evt\n",
    "from basic_viewing.units import Unit\n",
    "from basic_viewing.structure.core.basic_plot import plot_raster, sparse_raster\n",
    "from basic_viewing.structure.core import basic_plot as bp\n",
    "#from basic_viewing.structure import kwik_functions as kwf\n",
    "from decoder import linear as ld\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        '%(asctime)s %(name)-12s %(levelname)-8s %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.debug('all modules loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# bird and session\n",
    "bird = 'z007'\n",
    "sess = 'day-2016-09-10'\n",
    "syn_sess = 2\n",
    "# bird = 'z020'\n",
    "# sess = 'day-2016-06-03'\n",
    "\n",
    "exp_par = et.get_parameters(bird, sess)\n",
    "fn = et.file_names(bird, sess)\n",
    "song_file_path = et.file_path(fn, 'ss', 'sng')\n",
    "song_file = h5py.File(song_file_path, 'r')\n",
    "kwik_file = et.open_kwik(bird, sess)\n",
    "kwd_file = et.open_kwd(bird, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1 10 11 12 13 14 15 16 17 18 19  2 20 21 22 23 24 25 26 27 28 29  3 30\n",
      " 31 32 33 34 35 36 37 38 39  4 40 41 42 43 44 45 46 47 48 49  5 50 51 52 53\n",
      " 54 55 56 57 58 59  6 60 61 62 63  7  8  9]\n"
     ]
    }
   ],
   "source": [
    "# Neural data\n",
    "shank = 0\n",
    "shank_chans = prb_par['channel_groups'][shank]['channels']\n",
    "all_neural_chans = exp_par['channel_config']['neural']\n",
    "#m_starts = kwkf.apply_rec_offset(kwik_file, m.get_start(), m.get_rec())\n",
    "#m_starts = m.get_start()\n",
    "all_units = kwkf.list_units(kwik_file, group=shank, sorted=False)\n",
    "units_list = [Unit(clu, kwik_file=kwik_file) for clu in all_units.clu]\n",
    "\n",
    "# this returns a numpy recarray with cols:\n",
    "# group: site group (electrode shank)\n",
    "# clu: cluster number\n",
    "# qlt: sorting quality: 1 is MUA, 2 is well isolated (by default, only these 2 qlt's are returned)\n",
    "# For instance, see all the clusters that are either mua or good units.\n",
    "print(all_units['clu'])\n",
    "one_unit = units_list[4]\n",
    "unit_times, unit_recs = one_unit.get_time_stamps()\n",
    "\n",
    "#plt.plot(unit_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from streamtools import streams as st\n",
    "from threadtools import threadedfunction as td\n",
    "\n",
    "reload(st)\n",
    "def collect_frames_array(starts, span, s_f, kwd_file, recs_list, chan_list):\n",
    "    recs = np.unique(recs_list)\n",
    "    logger.info('Collecting {} recs...'.format(recs.size))\n",
    "    all_frames_array = []\n",
    "    for i_rec, rec in enumerate(recs):\n",
    "        starts_from_rec = starts[recs_list==rec]\n",
    "        logger.info(\"Rec {0}, {1} events ...\".format(rec, starts_from_rec.size))\n",
    "        stream_obj = st.H5Data(h5f.get_data_set(kwd_file, rec),\n",
    "                               s_f,\n",
    "                               chan_list=chan_list,\n",
    "                               dtype=np.float)\n",
    "        valid_starts = starts_from_rec[(starts_from_rec > 0) \n",
    "                                 & (starts_from_rec + span < stream_obj.n_samples)]\n",
    "        if valid_starts.size < starts_from_rec.size:\n",
    "            logger.warn('Some frames were out of bounds and will be discarded')\n",
    "            logger.warn('will collect only {0} events...'.format(valid_starts.size))\n",
    "        rec_frames = stream_obj.apply_repeated(valid_starts, span, lambda x: x)\n",
    "        all_frames_array.append(rec_frames)\n",
    "    logger.info('Done collecting')\n",
    "    return np.concatenate(all_frames_array, axis=0)\n",
    "\n",
    "reload(st)\n",
    "\n",
    "def get_unit_spikes(the_unit, kwd_file, chan_list, before=20, after=20):\n",
    "    s_f = the_unit.sampling_rate\n",
    "\n",
    "    valid_times = the_unit.time_samples[the_unit.time_samples > before]\n",
    "    \n",
    "    valid_recs = the_unit.recordings[the_unit.time_samples > before]\n",
    "    \n",
    "    if valid_times.size < the_unit.time_samples.size:\n",
    "            logger.warn('Some frames were out of left bounds and will be discarded')\n",
    "            logger.warn('will collect only {0} events...'.format(valid_times.size))\n",
    "            \n",
    "    return collect_frames_array(valid_times - before, \n",
    "                                      before + after, \n",
    "                                      s_f, \n",
    "                                      kwd_file, \n",
    "                                      valid_recs, \n",
    "                                      chan_list)\n",
    "\n",
    "\n",
    "def get_principal_channels(unit, projectors=3):\n",
    "    unit_path = os.path.split(os.path.abspath(unit.kwik_file.filename))[0]\n",
    "    all_features = np.load(os.path.join(unit_path, 'pc_features.npy'))\n",
    "    all_clusters = np.load(os.path.join(unit_path, 'spike_templates.npy'))\n",
    "    pc_ind = np.load(os.path.join(unit_path, 'pc_feature_ind.npy'))\n",
    "    \n",
    "    this_clu_n = unit.clu\n",
    "    # average across all the pc values of this cluster\n",
    "    clu_feat = all_features[np.where(all_clusters.flatten()==unit.clu)[0], :, :]\n",
    "    clu_mean_feat = np.abs(np.mean(clu_feat, axis=0))\n",
    "    \n",
    "    # larger projections\n",
    "    main_feat = (np.fliplr(np.argsort(clu_mean_feat, axis=1))[:,:projectors])\n",
    "    p_p = main_feat.reshape([1, -1], order='F').flatten()\n",
    "    indexes = np.unique(p_p, return_index=True)[1]\n",
    "    indexes.sort()\n",
    "    principal_projections = p_p[indexes]\n",
    "    \n",
    "    # channels projecting onto larger features\n",
    "    principal_channels = pc_ind[unit.clu][principal_projections]\n",
    "    \n",
    "    return principal_channels, principal_projections\n",
    "\n",
    "def save_unit_spikes(unit, spikes_array):\n",
    "    unit_path = os.path.split(os.path.abspath(unit.kwik_file.filename))[0]\n",
    "    file_folder = os.path.join(unit_path, 'unit_waveforms')\n",
    "    et.mkdir_p(file_folder)\n",
    "    file_path = os.path.join(file_folder, 'unit_{:03d}.npy'.format(unit.clu))\n",
    "    logger.info('Saving unit {0} in file {1}'.format(unit.clu, file_path))\n",
    "    return np.save(file_path, spikes_array)\n",
    "\n",
    "def get_all_spikes(unit_list, kwd_file, before=20, after=20):\n",
    "    for unit in unit_list:\n",
    "        logger.info('Unit clu_n {}'.format(unit.clu))\n",
    "        chans_list = get_principal_channels(unit, projectors=4)[0]\n",
    "        spikes = get_unit_spikes(unit, kwd_file, chans_list, before=before, after=after)\n",
    "        save_unit_spikes(unit, spikes)\n",
    "\n",
    "        \n",
    "def get_unit_folder(unit):\n",
    "    return os.path.split(os.path.abspath(unit.kwik_file.filename))[0]\n",
    "\n",
    "def load_unit_waveforms(unit):\n",
    "    folder = get_unit_folder(unit)\n",
    "    f_name = 'unit_{:03d}.npy'.format(unit.clu)\n",
    "    return np.load(os.path.join(folder, 'unit_waveforms', f_name))\n",
    "\n",
    "def get_avg_wave(unit):\n",
    "    return np.mean(load_unit_waveforms(unit), axis=0)\n",
    "\n",
    "def get_unit_main_chan(unit):\n",
    "    a_w_f = get_avg_wave(unit)\n",
    "    main_chan = np.argmax(np.ptp(avg_spikes, axis=0))\n",
    "    main_chan_absolute = get_principal_channels(unit)[0][main_chan]\n",
    "    return main_chan, main_chan_absolute\n",
    "\n",
    "def get_unit_main_wave(unit):\n",
    "    ch = get_unit_main_chan(unit)[0]\n",
    "    return load_unit_waveforms(unit)[:,:,ch]\n",
    "\n",
    "def get_unit_ptp(unit):\n",
    "    wf_main = get_unit_main_wave(unit)\n",
    "    all_ptp = wf_main.ptp(axis=1)\n",
    "    return np.median(all_ptp), np.std(all_ptp)\n",
    "        \n",
    "def get_all_unit_widths(unit):\n",
    "    logger.info('Getting width of all spikes from clu {}'.format(unit.clu))\n",
    "    wf_main = get_unit_main_wave(unit)\n",
    "    wf_samples = wf_main.shape[1]\n",
    "    mid_points = np.min(wf_main, axis=1) + np.ptp(wf_main, axis=1)/2.\n",
    "    mid_points_array = np.reshape(np.repeat(mid_points, wf_samples), [-1, wf_samples])\n",
    "    x, y = np.where(np.diff((wf_main>mid_points_array),1))\n",
    "    widths = []\n",
    "    for i in np.unique(x):\n",
    "        zero_xings = y[x==i]\n",
    "        if zero_xings.size>1:\n",
    "            widths.append(np.max(np.diff(y[x==i])))\n",
    "    \n",
    "    return np.array(widths)\n",
    "\n",
    "def get_unit_widths(unit):\n",
    "    widths = get_all_unit_widths(unit)\n",
    "    return np.median(widths), np.std(widths)\n",
    "\n",
    "def all_unit_widths(units_list):\n",
    "    logger.info('Getting widths of {} units'.format(len(units_list)))\n",
    "    return np.vstack([np.array(get_unit_widths(u)) for u in units_list])\n",
    "\n",
    "def all_unit_ptp(units_list):\n",
    "    logger.info('Getting heights of {} units'.format(len(units_list)))\n",
    "    return np.vstack([np.array(get_unit_ptp(u)) for u in units_list])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Debuggings: \n",
    "# p_chan, p_proj = get_principal_channels(units_list[32], projectors=4)        \n",
    "# get_all_spikes(units_list, kwd_file)\n",
    "# other_spikes = get_unit_spikes(units_list[32], kwd_file, all_neural_chans)\n",
    "# save_unit_spikes(units_list[32], other_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-06 15:31:27,731 threadtools.threadedfunction INFO     Starting function get_all_spikes in thread threadedFunction-4\n",
      "2016-12-06 15:31:27,753 root         INFO     Unit clu_n 0\n",
      "2016-12-06 15:31:28,371 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:31:28,374 root         INFO     Rec 0, 3632 events ...\n",
      "2016-12-06 15:31:29,775 root         INFO     Rec 1, 3311 events ...\n",
      "2016-12-06 15:31:31,263 root         INFO     Rec 2, 1765 events ...\n",
      "2016-12-06 15:31:31,813 root         INFO     Rec 3, 2576 events ...\n",
      "2016-12-06 15:31:33,088 root         INFO     Rec 4, 115260 events ...\n",
      "2016-12-06 15:32:54,415 root         INFO     Done collecting\n",
      "2016-12-06 15:32:54,592 root         INFO     Saving unit 0 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_000.npy\n",
      "2016-12-06 15:32:57,212 root         INFO     Unit clu_n 1\n",
      "2016-12-06 15:32:57,752 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:32:57,755 root         INFO     Rec 0, 117 events ...\n",
      "2016-12-06 15:32:57,814 root         INFO     Rec 1, 333 events ...\n",
      "2016-12-06 15:32:57,898 root         INFO     Rec 2, 142 events ...\n",
      "2016-12-06 15:32:57,947 root         INFO     Rec 3, 1087 events ...\n",
      "2016-12-06 15:32:58,305 root         INFO     Rec 4, 13083 events ...\n",
      "2016-12-06 15:33:05,062 root         INFO     Done collecting\n",
      "2016-12-06 15:33:05,077 root         INFO     Saving unit 1 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_001.npy\n",
      "2016-12-06 15:33:05,436 root         INFO     Unit clu_n 10\n",
      "2016-12-06 15:33:06,081 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:33:06,084 root         INFO     Rec 0, 4608 events ...\n",
      "2016-12-06 15:33:08,061 root         INFO     Rec 1, 4355 events ...\n",
      "2016-12-06 15:33:09,750 root         INFO     Rec 2, 2319 events ...\n",
      "2016-12-06 15:33:10,450 root         INFO     Rec 3, 4180 events ...\n",
      "2016-12-06 15:33:11,824 root         INFO     Rec 4, 227060 events ...\n",
      "2016-12-06 15:35:36,186 root         INFO     Done collecting\n",
      "2016-12-06 15:35:36,518 root         INFO     Saving unit 10 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_010.npy\n",
      "2016-12-06 15:35:42,204 root         INFO     Unit clu_n 11\n",
      "2016-12-06 15:35:42,758 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:35:42,762 root         INFO     Rec 0, 388 events ...\n",
      "2016-12-06 15:35:42,866 root         INFO     Rec 1, 447 events ...\n",
      "2016-12-06 15:35:43,001 root         INFO     Rec 2, 311 events ...\n",
      "2016-12-06 15:35:43,115 root         INFO     Rec 3, 248 events ...\n",
      "2016-12-06 15:35:43,183 root         INFO     Rec 4, 12515 events ...\n",
      "2016-12-06 15:35:48,121 root         INFO     Done collecting\n",
      "2016-12-06 15:35:48,172 root         INFO     Saving unit 11 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_011.npy\n",
      "2016-12-06 15:35:48,444 root         INFO     Unit clu_n 12\n",
      "2016-12-06 15:35:49,102 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:35:49,105 root         INFO     Rec 0, 1743 events ...\n",
      "2016-12-06 15:35:49,815 root         INFO     Rec 1, 1594 events ...\n",
      "2016-12-06 15:35:50,569 root         INFO     Rec 2, 923 events ...\n",
      "2016-12-06 15:35:50,967 root         INFO     Rec 3, 1142 events ...\n",
      "2016-12-06 15:35:51,448 root         INFO     Rec 4, 68259 events ...\n",
      "2016-12-06 15:36:41,200 root         INFO     Done collecting\n",
      "2016-12-06 15:36:41,353 root         INFO     Saving unit 12 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_012.npy\n",
      "2016-12-06 15:36:43,143 root         INFO     Unit clu_n 13\n",
      "2016-12-06 15:36:43,749 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:36:43,753 root         INFO     Rec 0, 28 events ...\n",
      "2016-12-06 15:36:43,773 root         INFO     Rec 1, 90 events ...\n",
      "2016-12-06 15:36:43,819 root         INFO     Rec 2, 32 events ...\n",
      "2016-12-06 15:36:43,838 root         INFO     Rec 3, 301 events ...\n",
      "2016-12-06 15:36:44,006 root         INFO     Rec 4, 2878 events ...\n",
      "2016-12-06 15:36:45,199 root         INFO     Done collecting\n",
      "2016-12-06 15:36:45,213 root         INFO     Saving unit 13 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_013.npy\n",
      "2016-12-06 15:36:45,330 root         INFO     Unit clu_n 14\n",
      "2016-12-06 15:36:45,877 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:36:45,880 root         INFO     Rec 0, 18 events ...\n",
      "2016-12-06 15:36:45,894 root         INFO     Rec 1, 88 events ...\n",
      "2016-12-06 15:36:45,936 root         INFO     Rec 2, 29 events ...\n",
      "2016-12-06 15:36:45,952 root         INFO     Rec 3, 216 events ...\n",
      "2016-12-06 15:36:46,033 root         INFO     Rec 4, 2200 events ...\n",
      "2016-12-06 15:36:46,585 root         INFO     Done collecting\n",
      "2016-12-06 15:36:46,589 root         INFO     Saving unit 14 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_014.npy\n",
      "2016-12-06 15:36:46,677 root         INFO     Unit clu_n 15\n",
      "2016-12-06 15:36:47,226 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:36:47,229 root         INFO     Rec 0, 805 events ...\n",
      "2016-12-06 15:36:47,562 root         INFO     Rec 1, 743 events ...\n",
      "2016-12-06 15:36:47,825 root         INFO     Rec 2, 481 events ...\n",
      "2016-12-06 15:36:47,992 root         INFO     Rec 3, 411 events ...\n",
      "2016-12-06 15:36:48,271 root         INFO     Rec 4, 24351 events ...\n",
      "2016-12-06 15:37:06,342 root         INFO     Done collecting\n",
      "2016-12-06 15:37:06,396 root         INFO     Saving unit 15 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_015.npy\n",
      "2016-12-06 15:37:07,337 root         INFO     Unit clu_n 16\n",
      "2016-12-06 15:37:07,996 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:37:08,000 root         INFO     Rec 0, 4115 events ...\n",
      "2016-12-06 15:37:09,278 root         INFO     Rec 1, 3994 events ...\n",
      "2016-12-06 15:37:10,524 root         INFO     Rec 2, 2109 events ...\n",
      "2016-12-06 15:37:11,089 root         INFO     Rec 3, 3341 events ...\n",
      "2016-12-06 15:37:11,990 root         INFO     Rec 4, 185065 events ...\n",
      "2016-12-06 15:38:34,704 root         INFO     Done collecting\n",
      "2016-12-06 15:38:34,916 root         INFO     Saving unit 16 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_016.npy\n",
      "2016-12-06 15:38:39,518 root         INFO     Unit clu_n 17\n",
      "2016-12-06 15:38:40,217 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:38:40,221 root         INFO     Rec 0, 5513 events ...\n",
      "2016-12-06 15:38:43,095 root         INFO     Rec 1, 5830 events ...\n",
      "2016-12-06 15:38:46,104 root         INFO     Rec 2, 2816 events ...\n",
      "2016-12-06 15:38:47,385 root         INFO     Rec 3, 4346 events ...\n",
      "2016-12-06 15:38:48,857 root         INFO     Rec 4, 261139 events ...\n",
      "2016-12-06 15:40:48,934 root         INFO     Done collecting\n",
      "2016-12-06 15:40:49,261 root         INFO     Saving unit 17 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_017.npy\n",
      "2016-12-06 15:40:54,773 root         INFO     Unit clu_n 18\n",
      "2016-12-06 15:40:55,433 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:40:55,436 root         INFO     Rec 0, 7898 events ...\n",
      "2016-12-06 15:40:57,954 root         INFO     Rec 1, 7125 events ...\n",
      "2016-12-06 15:41:00,738 root         INFO     Rec 2, 4191 events ...\n",
      "2016-12-06 15:41:01,917 root         INFO     Rec 3, 5899 events ...\n",
      "2016-12-06 15:41:03,741 root         INFO     Rec 4, 260969 events ...\n",
      "2016-12-06 15:42:52,383 root         INFO     Done collecting\n",
      "2016-12-06 15:42:52,772 root         INFO     Saving unit 18 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_018.npy\n",
      "2016-12-06 15:42:59,463 root         INFO     Unit clu_n 19\n",
      "2016-12-06 15:43:00,094 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:43:00,098 root         INFO     Rec 0, 3207 events ...\n",
      "2016-12-06 15:43:01,279 root         INFO     Rec 1, 3030 events ...\n",
      "2016-12-06 15:43:02,413 root         INFO     Rec 2, 1583 events ...\n",
      "2016-12-06 15:43:02,929 root         INFO     Rec 3, 5614 events ...\n",
      "2016-12-06 15:43:02,933 root         WARNING  Some frames were out of bounds and will be discarded\n",
      "2016-12-06 15:43:02,936 root         WARNING  will collect only 5613 events...\n",
      "2016-12-06 15:43:05,630 root         INFO     Rec 4, 204877 events ...\n",
      "2016-12-06 15:44:23,104 root         INFO     Done collecting\n",
      "2016-12-06 15:44:23,463 root         INFO     Saving unit 19 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_019.npy\n",
      "2016-12-06 15:44:29,594 root         INFO     Unit clu_n 2\n",
      "2016-12-06 15:44:30,207 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:44:30,210 root         INFO     Rec 0, 3637 events ...\n",
      "2016-12-06 15:44:31,485 root         INFO     Rec 1, 3549 events ...\n",
      "2016-12-06 15:44:32,676 root         INFO     Rec 2, 2020 events ...\n",
      "2016-12-06 15:44:33,379 root         INFO     Rec 3, 2302 events ...\n",
      "2016-12-06 15:44:34,350 root         INFO     Rec 4, 122718 events ...\n",
      "2016-12-06 15:45:36,727 root         INFO     Done collecting\n",
      "2016-12-06 15:45:37,011 root         INFO     Saving unit 2 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_002.npy\n",
      "2016-12-06 15:45:41,219 root         INFO     Unit clu_n 20\n",
      "2016-12-06 15:45:41,847 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:45:41,851 root         INFO     Rec 0, 379 events ...\n",
      "2016-12-06 15:45:42,183 root         INFO     Rec 1, 286 events ...\n",
      "2016-12-06 15:45:42,451 root         INFO     Rec 2, 102 events ...\n",
      "2016-12-06 15:45:42,512 root         INFO     Rec 3, 194 events ...\n",
      "2016-12-06 15:45:42,703 root         INFO     Rec 4, 22649 events ...\n",
      "2016-12-06 15:46:05,201 root         INFO     Done collecting\n",
      "2016-12-06 15:46:05,247 root         INFO     Saving unit 20 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_020.npy\n",
      "2016-12-06 15:46:05,863 root         INFO     Unit clu_n 21\n",
      "2016-12-06 15:46:06,483 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:46:06,487 root         INFO     Rec 0, 3845 events ...\n",
      "2016-12-06 15:46:09,964 root         INFO     Rec 1, 3504 events ...\n",
      "2016-12-06 15:46:12,132 root         INFO     Rec 2, 1729 events ...\n",
      "2016-12-06 15:46:13,007 root         INFO     Rec 3, 2802 events ...\n",
      "2016-12-06 15:46:17,479 root         INFO     Rec 4, 160902 events ...\n",
      "2016-12-06 15:48:26,706 root         INFO     Done collecting\n",
      "2016-12-06 15:48:26,954 root         INFO     Saving unit 21 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_021.npy\n",
      "2016-12-06 15:48:31,133 root         INFO     Unit clu_n 22\n",
      "2016-12-06 15:48:31,724 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:48:31,727 root         INFO     Rec 0, 2251 events ...\n",
      "2016-12-06 15:48:33,339 root         INFO     Rec 1, 2402 events ...\n",
      "2016-12-06 15:48:34,734 root         INFO     Rec 2, 1523 events ...\n",
      "2016-12-06 15:48:35,327 root         INFO     Rec 3, 1907 events ...\n",
      "2016-12-06 15:48:36,898 root         INFO     Rec 4, 83343 events ...\n",
      "2016-12-06 15:49:34,860 root         INFO     Done collecting\n",
      "2016-12-06 15:49:35,043 root         INFO     Saving unit 22 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_022.npy\n",
      "2016-12-06 15:49:37,199 root         INFO     Unit clu_n 23\n",
      "2016-12-06 15:49:37,817 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:49:37,821 root         INFO     Rec 0, 4036 events ...\n",
      "2016-12-06 15:49:39,427 root         INFO     Rec 1, 3656 events ...\n",
      "2016-12-06 15:49:40,871 root         INFO     Rec 2, 2310 events ...\n",
      "2016-12-06 15:49:41,741 root         INFO     Rec 3, 3071 events ...\n",
      "2016-12-06 15:49:43,901 root         INFO     Rec 4, 157426 events ...\n",
      "2016-12-06 15:51:00,215 root         INFO     Done collecting\n",
      "2016-12-06 15:51:00,484 root         INFO     Saving unit 23 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_023.npy\n",
      "2016-12-06 15:51:04,555 root         INFO     Unit clu_n 24\n",
      "2016-12-06 15:51:05,206 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:51:05,209 root         INFO     Rec 0, 3123 events ...\n",
      "2016-12-06 15:51:06,191 root         INFO     Rec 1, 2773 events ...\n",
      "2016-12-06 15:51:07,297 root         INFO     Rec 2, 1431 events ...\n",
      "2016-12-06 15:51:07,758 root         INFO     Rec 3, 2793 events ...\n",
      "2016-12-06 15:51:08,817 root         INFO     Rec 4, 193538 events ...\n",
      "2016-12-06 15:52:49,103 root         INFO     Done collecting\n",
      "2016-12-06 15:52:49,305 root         INFO     Saving unit 24 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_024.npy\n",
      "2016-12-06 15:52:52,547 root         INFO     Unit clu_n 25\n",
      "2016-12-06 15:52:53,118 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:52:53,122 root         INFO     Rec 0, 115 events ...\n",
      "2016-12-06 15:52:53,159 root         INFO     Rec 1, 141 events ...\n",
      "2016-12-06 15:52:53,232 root         INFO     Rec 2, 87 events ...\n",
      "2016-12-06 15:52:53,276 root         INFO     Rec 3, 83 events ...\n",
      "2016-12-06 15:52:53,321 root         INFO     Rec 4, 3241 events ...\n",
      "2016-12-06 15:52:54,152 root         INFO     Done collecting\n",
      "2016-12-06 15:52:54,168 root         INFO     Saving unit 25 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_025.npy\n",
      "2016-12-06 15:52:54,357 root         INFO     Unit clu_n 26\n",
      "2016-12-06 15:52:54,971 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:52:54,974 root         INFO     Rec 0, 4909 events ...\n",
      "2016-12-06 15:52:56,448 root         INFO     Rec 1, 4523 events ...\n",
      "2016-12-06 15:52:57,880 root         INFO     Rec 2, 2250 events ...\n",
      "2016-12-06 15:52:58,573 root         INFO     Rec 3, 3731 events ...\n",
      "2016-12-06 15:53:00,052 root         INFO     Rec 4, 263985 events ...\n",
      "2016-12-06 15:54:52,952 root         INFO     Done collecting\n",
      "2016-12-06 15:54:53,323 root         INFO     Saving unit 26 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_026.npy\n",
      "2016-12-06 15:54:59,869 root         INFO     Unit clu_n 27\n",
      "2016-12-06 15:55:00,517 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:55:00,521 root         INFO     Rec 0, 2779 events ...\n",
      "2016-12-06 15:55:01,858 root         INFO     Rec 1, 2448 events ...\n",
      "2016-12-06 15:55:02,818 root         INFO     Rec 2, 1259 events ...\n",
      "2016-12-06 15:55:03,213 root         INFO     Rec 3, 2432 events ...\n",
      "2016-12-06 15:55:04,051 root         INFO     Rec 4, 163586 events ...\n",
      "2016-12-06 15:56:22,750 root         INFO     Done collecting\n",
      "2016-12-06 15:56:22,928 root         INFO     Saving unit 27 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_027.npy\n",
      "2016-12-06 15:56:26,327 root         INFO     Unit clu_n 28\n",
      "2016-12-06 15:56:26,953 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:56:26,956 root         INFO     Rec 0, 4564 events ...\n",
      "2016-12-06 15:56:28,260 root         INFO     Rec 1, 3956 events ...\n",
      "2016-12-06 15:56:29,302 root         INFO     Rec 2, 2155 events ...\n",
      "2016-12-06 15:56:29,782 root         INFO     Rec 3, 3702 events ...\n",
      "2016-12-06 15:56:30,777 root         INFO     Rec 4, 151872 events ...\n",
      "2016-12-06 15:57:45,848 root         INFO     Done collecting\n",
      "2016-12-06 15:57:46,116 root         INFO     Saving unit 28 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_028.npy\n",
      "2016-12-06 15:57:50,121 root         INFO     Unit clu_n 29\n",
      "2016-12-06 15:57:50,714 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 15:57:50,717 root         INFO     Rec 0, 43 events ...\n",
      "2016-12-06 15:57:50,777 root         INFO     Rec 1, 79 events ...\n",
      "2016-12-06 15:57:50,830 root         INFO     Rec 2, 11 events ...\n",
      "2016-12-06 15:57:50,835 root         WARNING  Some frames were out of bounds and will be discarded\n",
      "2016-12-06 15:57:50,839 root         WARNING  will collect only 10 events...\n",
      "2016-12-06 15:57:50,846 root         INFO     Rec 3, 268 events ...\n",
      "2016-12-06 15:57:50,965 root         INFO     Rec 4, 4054 events ...\n",
      "2016-12-06 15:57:52,214 root         INFO     Done collecting\n",
      "2016-12-06 15:57:52,234 root         INFO     Saving unit 29 in file /mnt/cube/earneodo/bci_zf/ss_data/z007/day-2016-09-10/unit_waveforms/unit_029.npy\n",
      "2016-12-06 15:57:52,398 threadtools.threadedfunction INFO     done process threadedFunction-4\n"
     ]
    }
   ],
   "source": [
    "log_path = fn['folders']['ss']\n",
    "log_file = 'unit_collection.log'\n",
    "log_file_path = os.path.join(log_path, log_file)\n",
    "\n",
    "\n",
    "#handler = logging.StreamHandler()\n",
    "handler = logging.FileHandler(log_file_path)\n",
    "formatter = logging.Formatter(\n",
    "        '%(asctime)s %(name)-12s %(levelname)-8s (%(threadName)-10s) %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "threads = []\n",
    "\n",
    "collect_units = td.threadedFunction(args=(get_all_spikes,\n",
    "                                    units_list[:23],\n",
    "                                    kwd_file)\n",
    "                                    )\n",
    "collect_units.start()\n",
    "threads.append(collect_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_unit = units_list[23]\n",
    "a_unit.clu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-06 13:06:39,478 root         INFO     Collecting 1 recs...\n",
      "2016-12-06 13:06:39,480 root         INFO     Rec 2, 364 events ...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ecd9c7175fcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m all_frames = collect_frames_array(samples - 20, 40, \n\u001b[0;32m---> 14\u001b[0;31m                                   s_f, kwd_file, recs, chan_list)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-360494b97a92>\u001b[0m in \u001b[0;36mcollect_frames_array\u001b[0;34m(starts, span, s_f, kwd_file, recs_list, chan_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Some frames were out of bounds and will be discarded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'will collect only {0} events...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrec_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_repeated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mall_frames_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done collecting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/streamtools/streams.pyc\u001b[0m in \u001b[0;36mapply_repeated\u001b[0;34m(self, starts, window, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                               segment=[start, start + window]).data,\n\u001b[1;32m    206\u001b[0m                         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                         **kwargs) for start in starts]\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;31m#return results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/streamtools/streams.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sound, chan_list, segment)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchan_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/streamtools/streams.pyc\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, start, end, chan_list)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mchan_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchan_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         chunk_data = np.array(h5t.load_table_slice(self.data,\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a_unit = units_list[23]\n",
    "chan_list =  get_principal_channels(a_unit, projectors=3)[0]\n",
    "\n",
    "rec = 2\n",
    "s_f = a_unit.get_sampling_rate()\n",
    "samples = a_unit.time_samples[a_unit.recordings==rec]\n",
    "recs = a_unit.recordings[a_unit.recordings==rec]\n",
    "raw_table = st.H5Data(h5f.get_data_set(kwd_file, rec),\n",
    "                               s_f,\n",
    "                               chan_list=chan_list,\n",
    "                               dtype=np.float)\n",
    "\n",
    "all_frames = collect_frames_array(samples - 20, 40, \n",
    "                                  s_f, kwd_file, recs, chan_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-06 13:26:18,236 root         WARNING  Some frames were out of left bounds and will be discarded\n",
      "2016-12-06 13:26:18,239 root         WARNING  will collect only 68358 events...\n",
      "2016-12-06 13:26:18,243 root         INFO     Collecting 5 recs...\n",
      "2016-12-06 13:26:18,245 root         INFO     Rec 0, 1070 events ...\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "Can't read data (Wrong b-tree signature)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-4d2b3e6972e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_unit_spikes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwd_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbefore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-b41ffceca680>\u001b[0m in \u001b[0;36mget_unit_spikes\u001b[0;34m(the_unit, kwd_file, chan_list, before, after)\u001b[0m\n\u001b[1;32m     42\u001b[0m                                       \u001b[0mkwd_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                                       \u001b[0mvalid_recs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                                       chan_list)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-b41ffceca680>\u001b[0m in \u001b[0;36mcollect_frames_array\u001b[0;34m(starts, span, s_f, kwd_file, recs_list, chan_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Some frames were out of bounds and will be discarded'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'will collect only {0} events...'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_starts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrec_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_repeated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mall_frames_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done collecting'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/streamtools/streams.pyc\u001b[0m in \u001b[0;36mapply_repeated\u001b[0;34m(self, starts, window, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                               segment=[start, start + window]).data,\n\u001b[1;32m    206\u001b[0m                         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                         **kwargs) for start in starts]\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;31m#return results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/streamtools/streams.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sound, chan_list, segment)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Read the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchan_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchan_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/streamtools/streams.pyc\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, start, end, chan_list)\u001b[0m\n\u001b[1;32m    226\u001b[0m                                                              \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                                                              dtype=int),\n\u001b[0;32m--> 228\u001b[0;31m                                                    chan_list),\n\u001b[0m\u001b[1;32m    229\u001b[0m                               dtype=self.data_type)\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchunk_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/cube/earneodo/repos/swissknife/h5tools/tables.pyc\u001b[0m in \u001b[0;36mload_table_slice\u001b[0;34m(table, row_list, col_list)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mraw_table_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     table.read_direct(raw_table_slice,\n\u001b[0;32m--> 110\u001b[0;31m                       np.s_[np.min(row_list): np.max(row_list) + 1, np.min(col_list): np.max(col_list) + 1])\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;31m# return raw_table_slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mraw_table_slice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_list\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_list\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python2.7/site-packages/h5py-2.6.0-py2.7-linux-x86_64.egg/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36mread_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_sel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/usr/local/src/h5py/h5py/_objects.c:2845)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/usr/local/src/h5py/h5py/_objects.c:2803)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.read (/usr/local/src/h5py/h5py/h5d.c:3406)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw (/usr/local/src/h5py/h5py/_proxy.c:2002)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dread (/usr/local/src/h5py/h5py/_proxy.c:1650)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: Can't read data (Wrong b-tree signature)"
     ]
    }
   ],
   "source": [
    "u = get_unit_spikes(a_unit, kwd_file, chan_list, before=20, after=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-06 16:41:14,885 threadtools.threadedfunction INFO     Starting function all_unit_widths in thread threadedFunction-5\n",
      "2016-12-06 16:41:14,918 root         INFO     Getting width of all spikes from clu 0\n"
     ]
    }
   ],
   "source": [
    "log_path = fn['folders']['ss']\n",
    "log_file = 'width_collection.log'\n",
    "log_file_path = os.path.join(log_path, log_file)\n",
    "\n",
    "\n",
    "#handler = logging.StreamHandler()\n",
    "handler = logging.FileHandler(log_file_path)\n",
    "formatter = logging.Formatter(\n",
    "        '%(asctime)s %(name)-12s %(levelname)-8s (%(threadName)-10s) %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "threads = []\n",
    "\n",
    "\n",
    "collect_widths = td.threadedFunction(args=(all_unit_widths,\n",
    "                                    units_list)\n",
    "                                    )\n",
    "collect_widths.start()\n",
    "threads.append(collect_widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_h = all_unit_ptp(units_list[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1595.        ,   330.26562629],\n",
       "       [  425.        ,  1650.96014564],\n",
       "       [  963.        ,   384.59404681],\n",
       "       [ 2241.        ,   716.28559205],\n",
       "       [ 1760.        ,   433.39201352]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_h.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(0, 0, 3), (0, 1, 3), (0, 10, 3), (0, 11, 3), (0, 12, 3)], \n",
       "          dtype=[('group', '<i8'), ('clu', '<i8'), ('qlt', '<i8')])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_units = all_units[:5]\n",
    "some_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_units = some_units.size\n",
    "feat_dt = np.dtype([('w', np.float, 1), ('w_std', np.float, 1), ('h', np.float, 1), ('h_std', np.float, 1)])\n",
    "all_feats = np.recarray(n_units, dtype=feat_dt)\n",
    "all_feats['w'] = u_w.astype(float)[:,0]\n",
    "all_feats['w_std'] = u_w.astype(float)[:,1]\n",
    "all_feats['h'] = u_h.astype(float)[:,0]\n",
    "all_feats['h_std'] = u_h.astype(float)[:,1]\n",
    "\n",
    "import numpy.lib.recfunctions as rfn\n",
    "total_units = rfn.merge_arrays((some_units, all_feats), asrecarray=True, flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-06 17:55:39,810 root         INFO     Will compute features of 3 units\n",
      "2016-12-06 17:55:41,402 root         INFO     Getting width of all spikes from clu 12\n",
      "2016-12-06 17:56:07,976 root         INFO     Getting width of all spikes from clu 13\n",
      "2016-12-06 17:56:08,521 root         INFO     Getting width of all spikes from clu 14\n"
     ]
    }
   ],
   "source": [
    "def all_units_features(units_rec, kwik_file, write=True, path=None):\n",
    "    units_list = [Unit(clu, kwik_file=kwik_file) for clu in units_rec.clu]\n",
    "    n_units = units_rec.size\n",
    "    logger.info('Will compute features of {} units'.format(n_units))\n",
    "    u_h = all_unit_ptp(units_list)\n",
    "    u_w = all_unit_widths(units_list)\n",
    "    \n",
    "    feat_dt = np.dtype([('w', np.float, 1), \n",
    "                        ('w_std', np.float, 1), \n",
    "                        ('h', np.float, 1), \n",
    "                        ('h_std', np.float, 1)]\n",
    "                       )\n",
    "    all_feats = np.recarray(n_units, dtype=feat_dt)\n",
    "    all_feats['w'] = u_w.astype(float)[:,0]\n",
    "    all_feats['w_std'] = u_w.astype(float)[:,1]\n",
    "    all_feats['h'] = u_h.astype(float)[:,0]\n",
    "    all_feats['h_std'] = u_h.astype(float)[:,1]\n",
    "    total_units = rfn.merge_arrays((units_rec, all_feats), asrecarray=True, flatten=True)\n",
    "    if write:\n",
    "        path = get_unit_folder(units_list[0]) if path is None else path\n",
    "        np.save(os.path.join(path, 'units_features.npy'), total_units)\n",
    "    return total_units\n",
    "    \n",
    "rec_feat = all_units_features(all_units[4:7], kwik_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_features(bird, sess):\n",
    "    fn = et.file_names(bird, sess)\n",
    "    path = et.file_names(bird, sess)['folders']['ss']\n",
    "    return np.load(os.path.join(path, 'units_features.npy'))\n",
    "\n",
    "u_f = load_features(bird, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(0, 12, 3, 6.0, 3.036061805767721, 1760.0, 433.3920135175748),\n",
       " (0, 13, 3, 12.0, 6.902951901763023, 452.0, 1152.9606683706488),\n",
       " (0, 14, 3, 12.0, 7.368826380071477, 649.0, 1688.6430251644624)], \n",
       "          dtype=[('group', '<i8'), ('clu', '<i8'), ('qlt', '<i8'), ('w', '<f8'), ('w_std', '<f8'), ('h', '<f8'), ('h_std', '<f8')])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sess_unit_features(bird, sess, shank_list=None, write=True, path=None, sorted=False):\n",
    "    logger.info('Gonna get spike features of all units from bird {0} sess {1}'.format(bird, sess))\n",
    "    fn = et.file_names(bird, sess)\n",
    "    kwik_file = et.open_kwik(bird, sess)\n",
    "    \n",
    "    # Neural data\n",
    "    if shank_list is not None:\n",
    "        raise NotImplementedError('Kilosort doesnt use shanks, and I still didnt do this for klusta')\n",
    "    else:\n",
    "        shank = 0\n",
    "        \n",
    "    all_units = kwkf.list_units(kwik_file, group=shank, sorted=sorted)\n",
    "    all_unit_features = all_units_features(all_units, kwik_file, write=write, path=path)\n",
    "    return all_unit_features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-12-06 18:48:56,633 threadtools.threadedfunction INFO     Starting function sess_unit_features in thread threadedFunction-7\n",
      "2016-12-06 18:48:56,640 root         INFO     Gonna get spike features of all units from bird z007 sess day-2016-09-10\n",
      "2016-12-06 18:49:01,286 root         INFO     Will compute features of 64 units\n",
      "2016-12-06 18:49:01,289 root         INFO     Getting heights of 64 units\n"
     ]
    }
   ],
   "source": [
    "feat_thread = td.threadedFunction(args=(sess_unit_features, bird, sess))\n",
    "feat_thread.start()\n",
    "threads.append(feat_thread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
